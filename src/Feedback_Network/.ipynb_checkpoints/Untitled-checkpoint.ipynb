{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs:4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import save_image\n",
    "import torch.utils.data as data\n",
    "from PIL import Image \n",
    "import pickle\n",
    "from PIL import Image as im\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.metrics import Metric\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import argparse \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import clear_output\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "# CUDA for PyTorch\n",
    "print(\"Number of GPUs:\" + str(torch.cuda.device_count()))\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.no_grad()\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "trans = transforms.ToPILImage()\n",
    "trans1 = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(result_directory,named_parameters,model_name): \n",
    "    \n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(result_directory, model_name + \"gradient_flow.png\" ))\n",
    "    \n",
    "### Get all the children layers \n",
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = list(model.children())\n",
    "    flatt_children = []\n",
    "    if children == []:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for child in children:\n",
    "            try:\n",
    "                flatt_children.extend(get_children(child))\n",
    "            except TypeError:\n",
    "                flatt_children.append(get_children(child))\n",
    "    return flatt_children\n",
    "    \n",
    "\n",
    "### Layer Activation in CNNs \n",
    "\n",
    "    \n",
    "def visualise_layer_activation(model,local_batch,result_directory):\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    layer_name = 'conv1'\n",
    "    model.module.conv1.register_forward_hook(get_activation(layer_name))\n",
    "    output = model(local_batch)\n",
    "    act = activation[layer_name].squeeze()\n",
    "    print(act.shape)\n",
    "    #plot subplots for different images\n",
    "    for i in range(act[0].shape[0]):\n",
    "        output = im.fromarray(np.uint8(np.moveaxis(act[0][i].cpu().detach().numpy(), 0, -1))).convert('RGB')\n",
    "        output.save(os.path.join(result_directory,str(i)+'.png'))\n",
    "        #\n",
    "\n",
    "### Visualising Conv Filters\n",
    "def visualise_conv_filters(model,result_directory):\n",
    "    kernels = model.conv1.weight.detach()\n",
    "    print(kernels.shape)\n",
    "    # fig, axarr = plt.subplots(kernels.size(0))\n",
    "    # for i in range(kernels.shape[0]):\n",
    "    #     plt.savefig()\n",
    "    # for idx in range(kernels.size(0)):\n",
    "    #     axarr[idx].imsave(kernels[idx].squeeze(),result_directory + \"1.png\")\n",
    "    #\n",
    "    \n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "#########################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    c=0\n",
    "    images = []\n",
    "    list_name=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        list_name.append(os.path.join(folder,filename))\n",
    "    list_name.sort()\n",
    "    for filename in list_name:\n",
    "        img = cv2.imread(filename)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_train_load_data():\n",
    "    train= load_images_from_folder('/scratch/harsh_cnn/SR_data/train/x')\n",
    "    train_input=np.asarray(train)\n",
    "    print(train_input.shape)\n",
    "    train_input=np.moveaxis(train_input,1,-1)\n",
    "    train_input=np.moveaxis(train_input,1,-1)\n",
    "    train_input = train_input.astype(np.float32)\n",
    "\n",
    "    train= load_images_from_folder('/scratch/harsh_cnn/SR_data/train/y')\n",
    "    train_target=np.asarray(train)\n",
    "    train_target=np.moveaxis(train_target,1,-1)\n",
    "    train_target=np.moveaxis(train_target,1,-1)\n",
    "    train_target = train_target.astype(np.float32)\n",
    "\n",
    "    test= load_images_from_folder('/scratch/harsh_cnn/SR_data/test/x')\n",
    "    test_input=np.asarray(test)\n",
    "    test_input=np.moveaxis(test_input,1,-1)\n",
    "    test_input=np.moveaxis(test_input,1,-1)\n",
    "    test_input = test_input.astype(np.float32)\n",
    "\n",
    "    test= load_images_from_folder('/scratch/harsh_cnn/SR_data/test/y')\n",
    "    test_target=np.asarray(test)\n",
    "    test_target=np.moveaxis(test_target,1,-1)\n",
    "    test_target=np.moveaxis(test_target,1,-1)\n",
    "    test_target = test_target.astype(np.float32)\n",
    "    data_train=[]\n",
    "    data_test=[]\n",
    "    for input, target in zip(train_input, train_target):\n",
    "        data_train.append([input, target])\n",
    "    for input, target in zip(test_input, test_target):\n",
    "        data_test.append([input, target])\n",
    "\n",
    "    trainloader=torch.utils.data.DataLoader(dataset=data_train, batch_size=16, shuffle=True)\n",
    "    testloader=torch.utils.data.DataLoader(dataset=data_test, batch_size=16, shuffle=True)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = process_and_train_load_data ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def activation(act_type='relu', inplace=True, slope=0.2, n_prelu=1):\n",
    "    act_type = act_type.lower()\n",
    "    layer = None\n",
    "    if act_type == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act_type == 'lrelu':\n",
    "        layer = nn.LeakyReLU(slope, inplace)\n",
    "    elif act_type == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=slope)\n",
    "    else:\n",
    "        raise NotImplementedError('[ERROR] Activation layer [%s] is not implemented!'%act_type)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def norm(n_feature, norm_type='bn'):\n",
    "    norm_type = norm_type.lower()\n",
    "    layer = None\n",
    "    if norm_type =='bn':\n",
    "        layer = nn.BatchNorm2d(n_feature)\n",
    "    else:\n",
    "        raise NotImplementedError('[ERROR] Normalization layer [%s] is not implemented!'%norm_type)\n",
    "    return layer\n",
    "def sequential(*args):\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], OrderedDict):\n",
    "            raise NotImplementedError('[ERROR] %s.sequential() does not support OrderedDict'%sys.modules[__name__])\n",
    "        else:\n",
    "            return args[0]\n",
    "    modules = []\n",
    "    for module in args:\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for submodule in module:\n",
    "                modules.append(submodule)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            modules.append(module)\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "def pad(pad_type, padding):\n",
    "    pad_type = pad_type.lower()\n",
    "    if padding == 0:\n",
    "        return None\n",
    "\n",
    "    layer = None\n",
    "    if pad_type == 'reflect':\n",
    "        layer = nn.ReflectionPad2d(padding)\n",
    "    elif pad_type == 'replicate':\n",
    "        layer = nn.ReplicationPad2d(padding)\n",
    "    else:\n",
    "        raise NotImplementedError('[ERROR] Padding layer [%s] is not implemented!'%pad_type)\n",
    "    return layer\n",
    "def DeconvBlock(in_channels, out_channels, kernel_size, stride=1, dilation=1, bias=True, padding=0, \\\n",
    "                act_type='relu', norm_type='bn', pad_type='zero', mode='CNA'):\n",
    "\n",
    "    p = pad(pad_type, padding) if pad_type and pad_type != 'zero' else None\n",
    "    deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=bias)\n",
    "\n",
    "    if mode == 'CNA':\n",
    "        act = activation(act_type) if act_type else None\n",
    "        n = norm(out_channels, norm_type) if norm_type else None\n",
    "        return sequential(p, deconv, n, act)\n",
    "\n",
    "    \n",
    "def ConvBlock(in_channels, out_channels, kernel_size, stride=1, dilation=1, bias=True, valid_padding=True, padding=0,\\\n",
    "              act_type='relu', norm_type='bn', pad_type='zero', mode='CNA'):\n",
    "\n",
    "    if valid_padding:\n",
    "        padding = max(kernel_size-2,0)\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    p = pad(pad_type, padding) if pad_type and pad_type != 'zero' else None\n",
    "    conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n",
    "\n",
    "    if mode == 'CNA':\n",
    "        act = activation(act_type) if act_type else None\n",
    "        n = norm(out_channels, norm_type) if norm_type else None\n",
    "        return sequential(p, conv, n, act)\n",
    "\n",
    "\n",
    "class MeanShift(nn.Conv2d):\n",
    "    def __init__(self, rgb_mean, rgb_std, sign=-1):\n",
    "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
    "        std = torch.Tensor(rgb_std)\n",
    "        self.weight.data = torch.eye(3).view(3, 3, 1, 1)\n",
    "        self.weight.data.div_(std.view(3, 1, 1, 1))\n",
    "        self.bias.data = sign * 255. * torch.Tensor(rgb_mean)\n",
    "        self.bias.data.div_(std)\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "class FeedbackBlock(nn.Module):\n",
    "    def __init__(self, num_features, num_groups, upscale_factor, act_type, norm_type):\n",
    "        super(FeedbackBlock, self).__init__()\n",
    "        if upscale_factor == 2:\n",
    "            stride = 2\n",
    "            padding = 2\n",
    "            kernel_size = 6\n",
    "        elif upscale_factor == 3:\n",
    "            stride = 3\n",
    "            padding = 2\n",
    "            kernel_size = 7\n",
    "        elif upscale_factor == 4:\n",
    "            stride = 4\n",
    "            padding = 2\n",
    "            kernel_size = 8\n",
    "        elif upscale_factor == 8:\n",
    "            stride = 8\n",
    "            padding = 2\n",
    "            kernel_size = 12\n",
    "\n",
    "        self.num_groups = num_groups\n",
    "\n",
    "        self.compress_in = ConvBlock(2*num_features, num_features,\n",
    "                                     kernel_size=1,\n",
    "                                     act_type=act_type, norm_type=norm_type)\n",
    "\n",
    "        self.upBlocks = nn.ModuleList()\n",
    "        self.downBlocks = nn.ModuleList()\n",
    "        self.uptranBlocks = nn.ModuleList()\n",
    "        self.downtranBlocks = nn.ModuleList()\n",
    "\n",
    "        for idx in range(self.num_groups):\n",
    "            self.upBlocks.append(DeconvBlock(num_features, num_features,\n",
    "                                             kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                             act_type=act_type, norm_type=norm_type))\n",
    "            self.downBlocks.append(ConvBlock(num_features, num_features,\n",
    "                                             kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                             act_type=act_type, norm_type=norm_type, valid_padding=False))\n",
    "            if idx > 0:\n",
    "                self.uptranBlocks.append(ConvBlock(num_features*(idx+1), num_features,\n",
    "                                                   kernel_size=1, stride=1,\n",
    "                                                   act_type=act_type, norm_type=norm_type))\n",
    "                self.downtranBlocks.append(ConvBlock(num_features*(idx+1), num_features,\n",
    "                                                     kernel_size=1, stride=1,\n",
    "                                                     act_type=act_type, norm_type=norm_type))\n",
    "\n",
    "        self.compress_out = ConvBlock(num_groups*num_features, num_features,\n",
    "                                      kernel_size=1,\n",
    "                                      act_type=act_type, norm_type=norm_type)\n",
    "\n",
    "        self.should_reset = True\n",
    "        self.last_hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.should_reset:\n",
    "            self.last_hidden = torch.zeros(x.size()).cuda()\n",
    "            self.last_hidden.copy_(x)\n",
    "            self.should_reset = False\n",
    "\n",
    "        x = torch.cat((x, self.last_hidden), dim=1)\n",
    "        x = self.compress_in(x)\n",
    "\n",
    "        lr_features = []\n",
    "        hr_features = []\n",
    "        lr_features.append(x)\n",
    "\n",
    "        for idx in range(self.num_groups):\n",
    "            LD_L = torch.cat(tuple(lr_features), 1)    # when idx == 0, lr_features == [x]\n",
    "            if idx > 0:\n",
    "                LD_L = self.uptranBlocks[idx-1](LD_L)\n",
    "            LD_H = self.upBlocks[idx](LD_L)\n",
    "\n",
    "            hr_features.append(LD_H)\n",
    "\n",
    "            LD_H = torch.cat(tuple(hr_features), 1)\n",
    "            if idx > 0:\n",
    "                LD_H = self.downtranBlocks[idx-1](LD_H)\n",
    "            LD_L = self.downBlocks[idx](LD_H)\n",
    "\n",
    "            lr_features.append(LD_L)\n",
    "\n",
    "        del hr_features\n",
    "        output = torch.cat(tuple(lr_features[1:]), 1)   # leave out input x, i.e. lr_features[0]\n",
    "        output = self.compress_out(output)\n",
    "\n",
    "        self.last_hidden = output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.should_reset = True\n",
    "\n",
    "class SRFBN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_features, num_steps, num_groups, upscale_factor, act_type = 'prelu', norm_type = None):\n",
    "        super(SRFBN, self).__init__()\n",
    "\n",
    "        if upscale_factor == 2:\n",
    "            stride = 2\n",
    "            padding = 2\n",
    "            kernel_size = 6\n",
    "        elif upscale_factor == 3:\n",
    "            stride = 3\n",
    "            padding = 2\n",
    "            kernel_size = 7\n",
    "        elif upscale_factor == 4:\n",
    "            stride = 4\n",
    "            padding = 2\n",
    "            kernel_size = 8\n",
    "        elif upscale_factor == 8:\n",
    "            stride = 8\n",
    "            padding = 2\n",
    "            kernel_size = 12\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_features = num_features\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "        # RGB mean for DIV2K\n",
    "        rgb_mean = (0.4488, 0.4371, 0.4040)\n",
    "        rgb_std = (1.0, 1.0, 1.0)\n",
    "        self.sub_mean = MeanShift(rgb_mean, rgb_std)\n",
    "\n",
    "        # LR feature extraction block\n",
    "        self.conv_in = ConvBlock(in_channels, 4*num_features,\n",
    "                                 kernel_size=3,\n",
    "                                 act_type=act_type, norm_type=norm_type)\n",
    "        self.feat_in = ConvBlock(4*num_features, num_features,\n",
    "                                 kernel_size=1,\n",
    "                                 act_type=act_type, norm_type=norm_type)\n",
    "\n",
    "        # basic block\n",
    "        self.block = FeedbackBlock(num_features, num_groups, upscale_factor, act_type, norm_type)\n",
    "\n",
    "        # reconstruction block\n",
    "\t\t# uncomment for pytorch 0.4.0\n",
    "        # self.upsample = nn.Upsample(scale_factor=upscale_factor, mode='bilinear')\n",
    "\n",
    "        self.out = DeconvBlock(num_features, num_features,\n",
    "                               kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                               act_type='prelu', norm_type=norm_type)\n",
    "        self.conv_out = ConvBlock(num_features, out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  act_type=None, norm_type=norm_type)\n",
    "\n",
    "        self.add_mean = MeanShift(rgb_mean, rgb_std, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._reset_state()\n",
    "\n",
    "        x = self.sub_mean(x)\n",
    "\t\t# uncomment for pytorch 0.4.0\n",
    "        # inter_res = self.upsample(x)\n",
    "\t\t\n",
    "\t\t# comment for pytorch 0.4.0\n",
    "        inter_res = nn.functional.interpolate(x, scale_factor=self.upscale_factor, mode='bilinear', align_corners=False)\n",
    "        x = self.conv_in(x)\n",
    "        x = self.feat_in(x)\n",
    "\n",
    "        outs = []\n",
    "        for _ in range(self.num_steps):\n",
    "            h = self.block(x)\n",
    "\n",
    "            h = torch.add(inter_res, self.conv_out(self.out(h)))\n",
    "            h = self.add_mean(h)\n",
    "            outs.append(h)\n",
    "\n",
    "        return outs # return output of every timesteps\n",
    "\n",
    "    def _reset_state(self):\n",
    "        self.block.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Previous Checkpoint...\n",
      "Number of Parameters in Super Resolution Network\n",
      "+----------------------------------------+------------+\n",
      "|                Modules                 | Parameters |\n",
      "+----------------------------------------+------------+\n",
      "|        module.conv_in.0.weight         |    864     |\n",
      "|         module.conv_in.0.bias          |     32     |\n",
      "|        module.conv_in.1.weight         |     1      |\n",
      "|        module.feat_in.0.weight         |    256     |\n",
      "|         module.feat_in.0.bias          |     8      |\n",
      "|        module.feat_in.1.weight         |     1      |\n",
      "|   module.block.compress_in.0.weight    |    128     |\n",
      "|    module.block.compress_in.0.bias     |     8      |\n",
      "|   module.block.compress_in.1.weight    |     1      |\n",
      "|    module.block.upBlocks.0.0.weight    |    4096    |\n",
      "|     module.block.upBlocks.0.0.bias     |     8      |\n",
      "|    module.block.upBlocks.0.1.weight    |     1      |\n",
      "|    module.block.upBlocks.1.0.weight    |    4096    |\n",
      "|     module.block.upBlocks.1.0.bias     |     8      |\n",
      "|    module.block.upBlocks.1.1.weight    |     1      |\n",
      "|   module.block.downBlocks.0.0.weight   |    4096    |\n",
      "|    module.block.downBlocks.0.0.bias    |     8      |\n",
      "|   module.block.downBlocks.0.1.weight   |     1      |\n",
      "|   module.block.downBlocks.1.0.weight   |    4096    |\n",
      "|    module.block.downBlocks.1.0.bias    |     8      |\n",
      "|   module.block.downBlocks.1.1.weight   |     1      |\n",
      "|  module.block.uptranBlocks.0.0.weight  |    128     |\n",
      "|   module.block.uptranBlocks.0.0.bias   |     8      |\n",
      "|  module.block.uptranBlocks.0.1.weight  |     1      |\n",
      "| module.block.downtranBlocks.0.0.weight |    128     |\n",
      "|  module.block.downtranBlocks.0.0.bias  |     8      |\n",
      "| module.block.downtranBlocks.0.1.weight |     1      |\n",
      "|   module.block.compress_out.0.weight   |    128     |\n",
      "|    module.block.compress_out.0.bias    |     8      |\n",
      "|   module.block.compress_out.1.weight   |     1      |\n",
      "|          module.out.0.weight           |    4096    |\n",
      "|           module.out.0.bias            |     8      |\n",
      "|          module.out.1.weight           |     1      |\n",
      "|        module.conv_out.0.weight        |    216     |\n",
      "|         module.conv_out.0.bias         |     3      |\n",
      "+----------------------------------------+------------+\n",
      "Total Trainable Params: 22454\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c4edaa739899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0minitialize_train_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c4edaa739899>\u001b[0m in \u001b[0;36minitialize_train_network\u001b[0;34m(trainloader, testloader)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#             loss=loss1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtraining_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "def initialize_train_network(trainloader, testloader): \n",
    "    \n",
    "    results = \"/home/harsh.shukla/SRCNN/Codes/Feedback_Network/FBSR_results\"\n",
    "    \n",
    "    if not os.path.exists(results):\n",
    "        os.makedirs(results)\n",
    "        \n",
    "    # Initialising Checkpointing directory \n",
    "    checkpoints = os.path.join(results,\"Checkpoints\")\n",
    "    if not os.path.exists(checkpoints):\n",
    "        os.makedirs(checkpoints)\n",
    "    checkpoint_file = os.path.join(checkpoints,\"check.pt\")  \n",
    "    \n",
    "    # Initialising directory for Network Debugging\n",
    "    net_debug = os.path.join(results,\"Debug\")\n",
    "    if not os.path.exists(net_debug):\n",
    "        os.makedirs(net_debug)\n",
    "\n",
    "    model = SRFBN(3,3,8,2,2,4)\n",
    "    model = nn.DataParallel(model, device_ids = device_ids)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-8)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "#     criterion=nn.L1Loss().to(device)\n",
    "    \n",
    "    # load model if exists\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(\"Loading from Previous Checkpoint...\")\n",
    "        checkpoint = torch.load(checkpoint_file)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        model.train()\n",
    "    else:\n",
    "        print(\"No previous checkpoints exist, initialising network from start...\")\n",
    "        \n",
    "     ## Parameters in Networks\n",
    "    print(\"Number of Parameters in Super Resolution Network\")\n",
    "    count_parameters(model)\n",
    "    \n",
    "    best_loss=10000\n",
    "    train=[]\n",
    "    test=[]\n",
    "    model = model.to(device)\n",
    "   \n",
    "    loss1=0\n",
    "    for epoch in range(500):\n",
    "        training_loss=[]\n",
    "        test_loss=[]\n",
    "        list_no=0\n",
    "        for input_,target in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                input_ = input_.to(device)\n",
    "                target=target.to(device)\n",
    "            output = model(input_)\n",
    "            loss=criterion(output[-1], target)\n",
    "#             loss1=0\n",
    "#             for i in range (len(output)):\n",
    "#                 loss1+=criterion(output[i].to(device), target)\n",
    "#             loss=loss1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            training_loss.append(loss.item()*output[0].shape[0])\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            for local_batch, local_labels in testloader:\n",
    "                local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "                output = model(local_batch)\n",
    "                local_labels.require_grad = False\n",
    "                test_loss.append(criterion(output[-1], local_labels).item())\n",
    "        \n",
    "        torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, checkpoint_file)\n",
    "#         if(debug == True):\n",
    "#             plot_grad_flow(net_debug,model.named_parameters(),\"super_resolution_network\")\n",
    "#             label=im.fromarray(np.uint8(np.moveaxis(local_labels[0].cpu().detach().numpy(),0,-1))).convert('RGB')\n",
    "#             output=im.fromarray(np.uint8(np.moveaxis(output[0].cpu().detach().numpy(),0,-1))).convert('RGB')\n",
    "#             label.save(os.path.join(results,str(epoch) + 'test_target' + '.png'))\n",
    "#             output.save(os.path.join(results,str(epoch) + 'test_output' + '.png'))\n",
    "  \n",
    "        train.append(sum(training_loss)/len(training_loss))\n",
    "        test.append(sum(test_loss)/len(test_loss))\n",
    "        print(\"Epoch :\",epoch, flush=True)\n",
    "        print(\"Training loss :\",sum(training_loss)/len(training_loss),flush=True)\n",
    "        print(\"Test loss :\",sum(test_loss)/len(test_loss),flush=True)\n",
    "\n",
    "        print(\"-----------------------------------------------------------------------------------------------------------\")\n",
    "    try:\n",
    "        file = open(os.path.join(results,\"SR_train_loss.txt\"), 'w+')\n",
    "        try:\n",
    "            for i in range(len(test)):\n",
    "                file.write(str(train[i]) + \",\"  + str(test[i]))\n",
    "                file.write('\\n')\n",
    "        finally:\n",
    "            file.close()\n",
    "    except IOError:\n",
    "        print(\"Unable to create loss file\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Training Completed\")\n",
    "\n",
    "\n",
    "\n",
    "initialize_train_network(trainloader, testloader)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c9842ae80caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "output = model(local_batch)\n",
    "print(len(output))\n",
    "local_labels.require_grad = False\n",
    "print(criterion(output[-1], local_labels).item())\n",
    "test_loss.append(criterion(output[-1], local_labels).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
